{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oabez\\Anaconda3\\lib\\site-packages\\mxnet\\optimizer\\optimizer.py:167: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n",
      "  Optimizer.opt_registry[name].__name__))\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import autogluon as ag\n",
    "from autogluon import TabularPrediction as task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = read_csv(\"NTI_data/test.csv\")\n",
    "train_target = read_csv(\"NTI_data/train_target.csv\")\n",
    "transactions_test = read_csv(\"NTI_data/transactions_test.csv\")\n",
    "transactions_train = read_csv(\"NTI_data/transactions_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "#Признаки, связанные с суммой покупки\n",
    "agg_features=transactions_train.groupby('client_id')['amount_rur'].agg(['sum','mean','max']).reset_index()\n",
    "\n",
    "#Количество в каждой категории\n",
    "amount_of_purchase=transactions_train.groupby(['client_id','small_group'])['amount_rur'].count()\n",
    "counts_train=amount_of_purchase.reset_index().pivot(index='client_id', \\\n",
    "                                                      columns='small_group',values='amount_rur')\n",
    "counts_train=counts_train.fillna(0)\n",
    "counts_train.columns=['small_group_' + str(i) for i in counts_train.columns]\n",
    "\n",
    "#Сумма в каждой категории\n",
    "sum_of_group=transactions_train.groupby(['client_id','small_group'])['amount_rur'].sum()\n",
    "sum_train=sum_of_group.reset_index().pivot(index='client_id', \\\n",
    "                                                      columns='small_group',values='amount_rur')\n",
    "sum_train=sum_train.fillna(0)\n",
    "sum_train.columns=['small_group_sum_'+str(i) for i in sum_train.columns]\n",
    "\n",
    "#Минимум в каждой категории\n",
    "min_of_group=transactions_train.groupby(['client_id','small_group'])['amount_rur'].min()\n",
    "min_train=sum_of_group.reset_index().pivot(index='client_id', \\\n",
    "                                                      columns='small_group',values='amount_rur')\n",
    "min_train=min_train.fillna(0)\n",
    "min_train.columns=['small_group_min_'+str(i) for i in min_train.columns]\n",
    "\n",
    "#Максимум в каждой категории\n",
    "max_of_group=transactions_train.groupby(['client_id','small_group'])['amount_rur'].min()\n",
    "max_train=sum_of_group.reset_index().pivot(index='client_id', \\\n",
    "                                                      columns='small_group',values='amount_rur')\n",
    "max_train=max_train.fillna(0)\n",
    "max_train.columns=['small_group_max_'+str(i) for i in max_train.columns]\n",
    "\n",
    "#Средняя сумма в каждой категории\n",
    "avg_of_group=transactions_train.groupby(['client_id','small_group'])['amount_rur'].mean()\n",
    "avg_train=avg_of_group.reset_index().pivot(index='client_id', \\\n",
    "                                                      columns='small_group',values='amount_rur')\n",
    "avg_train=avg_train.fillna(0)\n",
    "avg_train.columns=['small_group_avg_'+str(i) for i in avg_train.columns]\n",
    "\n",
    "#Соединим все в одну таблицу\n",
    "counts_train=pd.merge(sum_train,counts_train,on='client_id')\n",
    "counts_train=pd.merge(avg_train,counts_train,on='client_id')\n",
    "counts_train=pd.merge(min_train,counts_train,on='client_id')\n",
    "counts_train=pd.merge(max_train,counts_train,on='client_id')\n",
    "train=pd.merge(train_target,agg_features,on='client_id')\n",
    "train=pd.merge(train,counts_train.reset_index(),on='client_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train.head(25000)\n",
    "test_data = train.tail(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20200309_164438/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20200309_164438/\n",
      "Train Data Rows:    25000\n",
      "Train Data Columns: 1015\n",
      "Preprocessing data ...\n",
      "Feature Generator processed 25000 data points with 1009 features\n",
      "Original Features:\n",
      "\tint features: 1\n",
      "\tfloat features: 1008\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tint features: 1\n",
      "\tfloat features: 1008\n",
      "\tData preprocessing and feature engineering runtime = 2.92s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: accuracy\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: accuracy\n",
      "C:\\Users\\oabez\\Anaconda3\\lib\\imp.py:342: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return _load(spec)\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n",
      "\t0.6042\t = Validation accuracy score\n",
      "\t122.73s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t0.6008\t = Validation accuracy score\n",
      "\t175.98s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t0.5989\t = Validation accuracy score\n",
      "\t201.81s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t0.6002\t = Validation accuracy score\n",
      "\t213.01s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t0.4518\t = Validation accuracy score\n",
      "\t80.59s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t0.4542\t = Validation accuracy score\n",
      "\t81.85s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "Warning: Low available memory may cause OOM error if training continues\n",
      "Available Memory: 440 MB\n",
      "Estimated GBM model size: 0 MB\n",
      "Warning: Early stopped GBM model prior to optimal result to avoid OOM error. Please increase available memory to avoid subpar model quality.\n",
      "  File \"C:\\Users\\oabez\\Anaconda3\\lib\\site-packages\\autogluon\\utils\\tabular\\ml\\trainer\\abstract_trainer.py\", line 276, in train_and_save\n",
      "    model = self.train_single(X_train, y_train, X_test, y_test, model, kfolds=kfolds, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, level=level, time_limit=time_limit)\n",
      "  File \"C:\\Users\\oabez\\Anaconda3\\lib\\site-packages\\autogluon\\utils\\tabular\\ml\\trainer\\abstract_trainer.py\", line 258, in train_single\n",
      "    model.fit(X=X_train, y=y_train, k_fold=kfolds, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=False, time_limit=time_limit, **model_fit_kwargs)\n",
      "  File \"C:\\Users\\oabez\\Anaconda3\\lib\\site-packages\\autogluon\\utils\\tabular\\ml\\models\\ensemble\\stacker_ensemble_model.py\", line 115, in fit\n",
      "    super().fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"C:\\Users\\oabez\\Anaconda3\\lib\\site-packages\\autogluon\\utils\\tabular\\ml\\models\\ensemble\\bagged_ensemble_model.py\", line 133, in fit\n",
      "    fold_model.fit(X_train=X_train, Y_train=y_train, X_test=X_test, Y_test=y_test, time_limit=time_limit_fold, **kwargs)\n",
      "  File \"C:\\Users\\oabez\\Anaconda3\\lib\\site-packages\\autogluon\\utils\\tabular\\ml\\models\\lgb\\lgb_model.py\", line 119, in fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"C:\\Users\\oabez\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\", line 264, in train\n",
      "    evaluation_result_list=evaluation_result_list))\n",
      "  File \"C:\\Users\\oabez\\Anaconda3\\lib\\site-packages\\autogluon\\utils\\tabular\\ml\\models\\lgb\\callbacks.py\", line 220, in _callback\n",
      "    best_iter[0] + 1, '\\t'.join([_format_eval_result(x) for x in best_score_list[0]])))\n",
      "Warning: Exception caused LightGBMClassifier_STACKER_l0 to fail during training... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\oabez\\Anaconda3\\lib\\site-packages\\autogluon\\utils\\tabular\\ml\\trainer\\abstract_trainer.py\", line 276, in train_and_save\n",
      "    model = self.train_single(X_train, y_train, X_test, y_test, model, kfolds=kfolds, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, level=level, time_limit=time_limit)\n",
      "  File \"C:\\Users\\oabez\\Anaconda3\\lib\\site-packages\\autogluon\\utils\\tabular\\ml\\trainer\\abstract_trainer.py\", line 258, in train_single\n",
      "    model.fit(X=X_train, y=y_train, k_fold=kfolds, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, compute_base_preds=False, time_limit=time_limit, **model_fit_kwargs)\n",
      "  File \"C:\\Users\\oabez\\Anaconda3\\lib\\site-packages\\autogluon\\utils\\tabular\\ml\\models\\ensemble\\stacker_ensemble_model.py\", line 115, in fit\n",
      "    super().fit(X=X, y=y, k_fold=k_fold, k_fold_start=k_fold_start, k_fold_end=k_fold_end, n_repeats=n_repeats, n_repeat_start=n_repeat_start, time_limit=time_limit, **kwargs)\n",
      "  File \"C:\\Users\\oabez\\Anaconda3\\lib\\site-packages\\autogluon\\utils\\tabular\\ml\\models\\ensemble\\bagged_ensemble_model.py\", line 133, in fit\n",
      "    fold_model.fit(X_train=X_train, Y_train=y_train, X_test=X_test, Y_test=y_test, time_limit=time_limit_fold, **kwargs)\n",
      "  File \"C:\\Users\\oabez\\Anaconda3\\lib\\site-packages\\autogluon\\utils\\tabular\\ml\\models\\lgb\\lgb_model.py\", line 119, in fit\n",
      "    self.model = lgb.train(**train_params)\n",
      "  File \"C:\\Users\\oabez\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\", line 264, in train\n",
      "    evaluation_result_list=evaluation_result_list))\n",
      "  File \"C:\\Users\\oabez\\Anaconda3\\lib\\site-packages\\autogluon\\utils\\tabular\\ml\\models\\lgb\\callbacks.py\", line 220, in _callback\n",
      "    best_iter[0] + 1, '\\t'.join([_format_eval_result(x) for x in best_score_list[0]])))\n",
      "TypeError: 'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t0.6319\t = Validation accuracy score\n",
      "\t932.98s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n"
     ]
    }
   ],
   "source": [
    "predictor = task.fit(train_data=train_data, label='bins', problem_type=\"multiclass\", auto_stack=True)\n",
    "performance = predictor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
